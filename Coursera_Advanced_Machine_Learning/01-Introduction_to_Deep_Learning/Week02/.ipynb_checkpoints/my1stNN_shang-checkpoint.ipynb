{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my1stNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "\n",
    "- Code a deep (with at least 1 hidden layer) neural network in tensorflow\n",
    "\n",
    "- Fit it on the train dataset, estimate quality on the test dataset\n",
    "\n",
    "- Plot the train loss and test loss as a function of the training iteration number\n",
    "\n",
    "### Long description\n",
    "\n",
    "Your ultimate task for this part is to build your first neural network [almost] from scratch and pure tensorflow. This time you will have the same digit recognition problem as for the logistic regression assignment, but at a larger scale:\n",
    "\n",
    "- images are now 28x28\n",
    "\n",
    "- 10 different digits\n",
    "\n",
    "- 50k samples\n",
    "\n",
    "Note that you are not required to build 152-layer monsters here. A 2-layer (one hidden, one output) NN should already have an edge over logistic regression.\n",
    "\n",
    "[bonus score] If you've already beaten logistic regression with a two-layer net, but enthusiasm still ain't gone, you can try improving the test accuracy even further! The milestones would be 95%/97.5%/98.5% accuracy on the test set.\n",
    "\n",
    "Please use the preprocessed_mnist.py in week2 folder to load the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPOILERS!\n",
    "\n",
    "### Recommended pipeline:\n",
    "\n",
    "- Begin with logistic regression from the previous assignment to classify some number against others (e.g. zero vs nonzero)\n",
    "\n",
    "- Generalize it to multiclass logistic regression. Either try to remember the week 1 lectures or google it.\n",
    "- Instead of a weights vector you'll have to use a matrix with `shape=(features, classes)`\n",
    "- softmax (exp over sum of exps) can implemented manually or as `tf.nn.softmax`\n",
    "- probably better to use STOCHASTIC gradient descent (minibatch)\n",
    "- in which case sample should probably be shuffled (or use random subsamples on each iteration)\n",
    "\n",
    "### Add a hidden layer. Now your logistic regression uses hidden neurons instead of inputs.\n",
    "\n",
    "- Hidden layer uses the same math as output layer (ex-logistic regression), but uses some nonlinearity (sigmoid) instead of softmax\n",
    "- You need to train both layers, not just output layer :)\n",
    "- Do not initialize layers with zeros (due to symmetry effects). A gaussian noize with small sigma will do.\n",
    "- 50 hidden neurons and a sigmoid nonlinearity will do for a start. Many ways to improve here.\n",
    "- In an ideal case this totals to 2 .dot's, 1 softmax and 1 sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUP8PRZ8Vlgh2BcUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import package \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (50000, 28, 28)\n",
      "y_train: (50000,)\n",
      "X_val: (10000, 28, 28)\n",
      "y_val: (10000,)\n",
      "X_test: (10000, 28, 28)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train:',X_train.shape)\n",
    "print('y_train:',y_train.shape)\n",
    "print('X_val:',X_val.shape)\n",
    "print('y_val:',y_val.shape)\n",
    "print('X_test:',X_test.shape)\n",
    "print('y_test:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "node = 50\n",
    "n_val = 784\n",
    "n_y = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape data\n",
    "X_train_T = np.reshape(X_train,(X_train.shape[0],n_val))\n",
    "X_val_T = np.reshape(X_val,(X_val.shape[0],n_val))\n",
    "X_test_T = np.reshape(X_test,(X_test.shape[0],n_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 10)\n",
      "(50000, 10) (10000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# One hot encode\n",
    "y_all = np.concatenate([y_train,y_val,y_test])\n",
    "\n",
    "ses_one_hot = tf.Session()\n",
    "tf_one_hot = tf.one_hot(y_all,n_y,1,0)  \n",
    "with tf.Session() as sess:  \n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "    y_one_hot =sess.run(tf_one_hot)\n",
    "    sess.close()\n",
    "print(y_one_hot.shape)\n",
    "# Check shape\n",
    "y_train_ot = y_one_hot[:50000,:]\n",
    "y_val_ot = y_one_hot[50000:60000,:]\n",
    "y_test_ot = y_one_hot[60000:70000,:]\n",
    "print(y_train_ot.shape,y_val_ot.shape,y_test_ot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_X:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"input_y:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Placeholders for the input data\n",
    "X_input = tf.placeholder(tf.float32, [None,n_val],name=\"input_X\")\n",
    "y_input = tf.placeholder(tf.float32, [None,n_y],name=\"input_y\")\n",
    "print (X_input)\n",
    "print (y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Model Parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "tf.set_random_seed(225)\n",
    "\n",
    "w1 = tf.get_variable(\"w1\", [n_val, node], dtype=\"float32\", initializer = tf.contrib.layers.xavier_initializer(seed = 225))\n",
    "\n",
    "w2 = tf.get_variable(\"w2\", [node, n_y], dtype=\"float32\", initializer = tf.contrib.layers.xavier_initializer(seed = 225))\n",
    "\n",
    "b1 = tf.get_variable(\"b1\", [1, node], dtype=\"float32\", initializer = tf.zeros_initializer())\n",
    "\n",
    "b2 = tf.get_variable(\"b2\", [1, 10], dtype=\"float32\", initializer = tf.zeros_initializer())\n",
    "\n",
    "parameters = {\"w1\": w1,\"b1\": b1,\"w2\": w2,\"b2\": b2}\n",
    "\n",
    "hidden_out = tf.nn.sigmoid(tf.add(tf.matmul(X_input,w1), b1))\n",
    "\n",
    "predicted_y = tf.add(tf.matmul(hidden_out,w2),b2)\n",
    "## Loss \n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = predicted_y, labels = y_input))\n",
    "\n",
    "#optimizer = tf.train.AdamOptimizer(0.001).minimize(lossï¼‰\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "num_epochs = 10\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as s:\n",
    "    s.run(init)\n",
    "    epoch_cost = []\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        _ , loss_temp = s.run([optimizer, loss], feed_dict={X_input: X_train_T, y_input: y_train_ot})\n",
    "        \n",
    "        epoch_cost.append(loss_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n24e+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "\n",
    "\n",
    "plt.plot(np.squeeze(epoch_cost))\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    492\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    175\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    164\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 165\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    166\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f0dd5ab5a504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# parameters = {\"w1\": w1,\"b1\": b1,\"w2\": w2,\"b2\": b2}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorrect_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_val_T\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_val_ot\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(input, axis, name, dimension)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot specify both 'axis' and 'dimension'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36marg_max\u001b[0;34m(input, dimension, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m   \"\"\"\n\u001b[1;32m    167\u001b[0m   result = _op_def_lib.apply_op(\"ArgMax\", input=input, dimension=dimension,\n\u001b[0;32m--> 168\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    169\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;31m# What type does convert_to_tensor think it has?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             observed = ops.internal_convert_to_tensor(\n\u001b[0;32m--> 504\u001b[0;31m                 values, as_ref=input_arg.is_ref).dtype.name\n\u001b[0m\u001b[1;32m    505\u001b[0m             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n\u001b[1;32m    506\u001b[0m                       (input_name, op_type_name, observed))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    174\u001b[0m                                          as_ref=False):\n\u001b[1;32m    175\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 165\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    166\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "# parameters = {\"w1\": w1,\"b1\": b1,\"w2\": w2,\"b2\": b2}\n",
    "correct_prediction = tf.equal(tf.argmax(tf.transpose(predicted_y)), tf.argmax(tf.transpose(y_input)))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print(accuracy.eval({X_input:X_val_T , y_input: y_val_ot}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
